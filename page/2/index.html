<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> In un'altra vita</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/mugen.ico"><link rel="stylesheet" href="/css/apollo.css"><!-- link(rel="stylesheet", href=url_for("https://highlightjs.org/static/demo/styles/" + (theme.codestyle ? theme.codestyle : 'solarized-light') + ".css"))--><link rel="search" type="application/opensearchdescription+xml" href="https://lamply.github.io/atom.xml" title="In un'altra vita"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/mugen.ico" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/Lamply" target="_blank" class="nav-list-link">GITHUB</a></li></ul></header><main class="container"><ul class="home post-list"><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/03/01/DeepLab/" class="post-title-link">DeepLab系列论文简略记录</a></h2><div class="tags"><a href="/tags/论文笔记/" class="tag-title">#论文笔记</a></div><div class="post-info">Mar 1, 2018</div><div class="post-content"><p>这部分是关于语义分割网络 DeepLab 系列的三篇论文。尽管经验性的技巧很多，但就效果而言还是很不错的，有不少值得参考的地方。<br></p></div><a href="/2018/03/01/DeepLab/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/03/01/MobileNetsV2/" class="post-title-link">MobileNet V2</a></h2><div class="tags"><a href="/tags/论文笔记/" class="tag-title">#论文笔记</a></div><div class="post-info">Mar 1, 2018</div><div class="post-content"><p>这是关于轻量级网络 MobileNet 的改进版论文，作为万众瞩目的高效率骨干网络架构，它的更新意味着移动端网络的又一次改进。<br>原文链接： <a href="https://arxiv.org/pdf/1801.04381.pdf" target="_blank" rel="noopener">Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation</a><br></p></div><a href="/2018/03/01/MobileNetsV2/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/03/01/ShuffleNet/" class="post-title-link">ShuffleNet</a></h2><div class="tags"><a href="/tags/论文笔记/" class="tag-title">#论文笔记</a></div><div class="post-info">Mar 1, 2018</div><div class="post-content"><p>这部分是关于轻量级网络 ShuffleNet 的论文记录，主要是基于 channel shuffle 的想法来减少 CNN 中占大头的 1x1 卷积的计算量。<br></p></div><a href="/2018/03/01/ShuffleNet/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/11/15/Low_Rank/" class="post-title-link">Coordinating Filters for Faster Deep Neural Networks</a></h2><div class="tags"><a href="/tags/论文笔记/" class="tag-title">#论文笔记</a></div><div class="post-info">Nov 15, 2017</div><div class="post-content"><div align="center">
<img src="/2017/11/15/Low_Rank/ForceRegularization.png">  
</div>

<p>这篇论文是在学习压缩模型时无意中看到的，发表在 ICCV 2017。因为看到它的 motivation 觉得挺有意思的（昴星团瞩目），刚好还有代码，于是就学习了一下，顺带看看能不能用在项目上。  </p>
<p>原文链接： <a href="https://arxiv.org/abs/1703.09746" target="_blank" rel="noopener">Coordinating Filters for Faster Deep Neural Networks</a><br></p></div><a href="/2017/11/15/Low_Rank/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/10/17/Kaggle/" class="post-title-link">Kaggle "Amazon from Space" 经验分享</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a></div><div class="post-info">Oct 17, 2017</div><div class="post-content"><p>看了 Kaggle 亚马逊雨林卫星图分类比赛第一名 <a href="http://blog.kaggle.com/2017/10/17/planet-understanding-the-amazon-from-space-1st-place-winners-interview/" target="_blank" rel="noopener">Planet: Understanding the Amazon from Space, 1st Place Winner’s Interview</a>, 学到了些 trick, 这里记录一下<br></p></div><a href="/2017/10/17/Kaggle/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/09/01/ResNet/" class="post-title-link">ResNet</a></h2><div class="tags"><a href="/tags/论文简译/" class="tag-title">#论文简译</a></div><div class="post-info">Sep 1, 2017</div><div class="post-content"><p>这里是 ResNet 的论文，作为被广泛应用的骨干网络，它提出的几个概念可以说是<strong>着实可靠</strong>地拓宽了网络设计的思路，对于广大摸着石头过河的工程师和研究者来说就是指出了一条明路。网络本身也高效、简洁且实用，可以作为 VGG 的上位替代。<br></p></div><a href="/2017/09/01/ResNet/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2017/09/01/GoogLeNet/" class="post-title-link">GoogLeNet系列</a></h2><div class="tags"><a href="/tags/论文简译/" class="tag-title">#论文简译</a></div><div class="post-info">Sep 1, 2017</div><div class="post-content"><p>这部分是关于 GoogLeNet 系列网络的两篇论文，涵盖了 Inception v1 到 v3。作为 CNN 发展进程中经典的模型，它通过大量实验思考总结了很多关于 CNN 在设计方面应当注意的事项，尽管没有 VGG 那般简洁好用易训练，而且工程设计感很浓重，但其中涉及到的各种实验和结果都是实打实的，对这些实验的解读可以印证和加深自己对深度神经网络的理解，建议参考原文。  </p>
<p>Going deeper with convolutions:<br><a href="https://arxiv.org/pdf/1409.4842.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1409.4842.pdf</a>  </p>
<p>Rethinking the Inception Architecture for Computer Vision:<br><a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1512.00567.pdf</a>  </p></div><a href="/2017/09/01/GoogLeNet/" class="read-more">...阅读全文</a></article></li></ul></main><footer><div class="paginator"><a href="/" class="prev">上一页</a></div><div class="copyright"><p>© 2015 - 2019 <a href="https://lamply.github.io">Lamply</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>