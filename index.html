<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> In un'altra vita</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/mugen.ico"><link rel="stylesheet" href="/css/apollo.css"><!-- link(rel="stylesheet", href=url_for("https://highlightjs.org/static/demo/styles/" + (theme.codestyle ? theme.codestyle : 'solarized-light') + ".css"))--><link rel="search" type="application/opensearchdescription+xml" href="https://lamply.github.io/atom.xml" title="In un'altra vita"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/mugen.ico" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link active">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://github.com/Lamply" target="_blank" class="nav-list-link">GITHUB</a></li></ul></header><main class="container"><ul class="home post-list"><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2019/04/19/protrait-segmentation/" class="post-title-link">人像分割</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a><a href="/tags/语义分割/" class="tag-title">#语义分割</a></div><div class="post-info">Apr 19, 2019</div><div class="post-content"><div align="center">
<img src="/2019/04/19/protrait-segmentation/Einstein.png" width="70%">  
</div>

<p>这部分是关于在低计算量下完成人像分割的工作，因为时间充裕，所以调查尝试得比较多，最终完成的效果还不错。<br></p></div><a href="/2019/04/19/protrait-segmentation/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/08/07/Low_Rank_Research/" class="post-title-link">关于 LRA 和 Force Regularization 的探索</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a><a href="/tags/模型加速和压缩/" class="tag-title">#模型加速和压缩</a></div><div class="post-info">Aug 7, 2018</div><div class="post-content"><p>这部分是将《Coordinating Filters for Faster Deep Neural Networks》中提到的 <em>Force Regularization</em> 和 <em>LRA</em> 用于实际项目的效果，虽然现在看来不是很严谨，不过算是一次很好的尝试。<br></p></div><a href="/2018/08/07/Low_Rank_Research/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/08/07/caffe_things/" class="post-title-link">Caffe使用问题记录</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a><a href="/tags/问题记录/" class="tag-title">#问题记录</a><a href="/tags/caffe/" class="tag-title">#caffe</a></div><div class="post-info">Aug 7, 2018</div><div class="post-content"><p>以往在使用 caffe 中遇到的部分问题记录。<br></p></div><a href="/2018/08/07/caffe_things/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/07/19/face-alignment-cnn/" class="post-title-link">深度学习方法的人脸对齐</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a><a href="/tags/人脸对齐/" class="tag-title">#人脸对齐</a></div><div class="post-info">Jul 19, 2018</div><div class="post-content"><figure align="center">
<img src="/2018/07/19/face-alignment-cnn/1.png">
</figure>

<p>这部分是去年 9 月份开始的工作，算是第一次真正踏入深度学习的领域。具体工作也还算简单，就是复现一篇深度学习方法做的人脸对齐，当练练手。<br></p></div><a href="/2018/07/19/face-alignment-cnn/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/07/15/face-alignment/" class="post-title-link">传统方法的人脸对齐</a></h2><div class="tags"><a href="/tags/技术经验/" class="tag-title">#技术经验</a><a href="/tags/人脸对齐/" class="tag-title">#人脸对齐</a></div><div class="post-info">Jul 15, 2018</div><div class="post-content"><p><div align="center">
<img src="/2018/07/15/face-alignment/1.png">  
</div><br>这里是关于应用传统方法做人脸对齐的经验总结，是在去年5月到7月的工作，也是我入职后的第一个正式项目，用的是 SDM (Supervised Descent Method) [1] 的方法，具体细节可能不太记得，所以会慢慢补完。<br></p></div><a href="/2018/07/15/face-alignment/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/07/11/一致性完全性与几何学/" class="post-title-link">《哥德尔·艾舍尔·巴赫——集异璧之大成》其四</a></h2><div class="tags"><a href="/tags/读书笔记/" class="tag-title">#读书笔记</a></div><div class="post-info">Jul 11, 2018</div><div class="post-content"><p>本文是 GEB 的第四章部分阅读笔记，这章开始深入对形式系统的意义起效做讨论，介绍了一致性、完全性，还有用于阐述未定义项的几何发展史。<br></p></div><a href="/2018/07/11/一致性完全性与几何学/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/06/28/图形与衬底/" class="post-title-link">《哥德尔·艾舍尔·巴赫——集异璧之大成》其三</a></h2><div class="tags"><a href="/tags/读书笔记/" class="tag-title">#读书笔记</a></div><div class="post-info">Jun 28, 2018</div><div class="post-content"><p>本文是 GEB 的第三章部分阅读笔记，内容多是我自己筛选、压缩、重排的，并尽可能的保留书中名词的译名和说法。因为我只有非数学系普通理工科大学生的数学基础，不怎么熟悉数论逻辑学什么的，所以可能会有某些错误的理解或说法，就酱。<br></p></div><a href="/2018/06/28/图形与衬底/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/06/27/关于形式系统/" class="post-title-link">《哥德尔·艾舍尔·巴赫——集异璧之大成》其二</a></h2><div class="tags"><a href="/tags/读书笔记/" class="tag-title">#读书笔记</a></div><div class="post-info">Jun 27, 2018</div><div class="post-content"><p>本文是「GEB」第二、三章的读书笔记，这部分是边读边记，同时忽略了一些详细严谨的解释和讨论。<br></p></div><a href="/2018/06/27/关于形式系统/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/06/21/WU谜题/" class="post-title-link">《哥德尔·艾舍尔·巴赫——集异璧之大成》其一</a></h2><div class="tags"><a href="/tags/读书笔记/" class="tag-title">#读书笔记</a></div><div class="post-info">Jun 21, 2018</div><div class="post-content"><p>学习之余看起了以前没看完的书，顺便把博客环境重新搭了起来。<br></p></div><a href="/2018/06/21/WU谜题/" class="read-more">...阅读全文</a></article></li><li class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/04/19/zero-kernels/" class="post-title-link">零核现象</a></h2><div class="tags"><a href="/tags/观测/" class="tag-title">#观测</a></div><div class="post-info">Apr 19, 2018</div><div class="post-content"><p><div align="center">
<img src="/2018/04/19/zero-kernels/TingMengDe.bmp">  
</div><br>这里是对零核现象的观察实验记录.<br>具体来说, 就是在训练卷积神经网络的过程中发现模型中有大量卷积核的 L1 变为 0 的情况, 这里为了方便简称零核现象.<br></p></div><a href="/2018/04/19/zero-kernels/" class="read-more">...阅读全文</a></article></li></ul></main><footer><div class="paginator"><a href="/page/2/" class="next">下一页</a></div><div class="copyright"><p>© 2015 - 2019 <a href="https://lamply.github.io">Lamply</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>